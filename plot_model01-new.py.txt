import argparse
import os
import torch
import numpy as np
from attrdict import AttrDict
import matplotlib.pyplot as plt 
from matplotlib import animation

from sgan.data.loader import data_loader
from sgan.models import TrajectoryGenerator
from sgan.losses import displacement_error, final_displacement_error
from sgan.utils import relative_to_abs, get_dset_path

parser = argparse.ArgumentParser()
parser.add_argument('--model_path', type=str)
parser.add_argument('--num_samples', default=20, type=int)
parser.add_argument('--dset_type', default='test', type=str)

fake_tracks, real_tracks = [], []
cf_fakes_x, cf_fakes_y = [], []
cf_reals_x, cf_reals_y = [], []
fake_graph, real_graph = [], []


def gen_dot():
    for i in range(0, len(fake_tracks)):
        yield (real_tracks[i], fake_tracks[i])


def update_dot(newd):
    cf_reals_x.append(newd[0][0])
    cf_reals_y.append(newd[0][1])
    cf_fakes_x.append(newd[1][0])
    cf_fakes_y.append(newd[1][1])
    real_graph.set_data(cf_reals_x, cf_reals_y)
    fake_graph.set_data(cf_fakes_x, cf_fakes_y)
    return fake_graph,


def get_generator(checkpoint):
    args = AttrDict(checkpoint['args'])
    generator = TrajectoryGenerator(
        obs_len=args.obs_len,
        pred_len=args.pred_len,
        embedding_dim=args.embedding_dim,
        encoder_h_dim=args.encoder_h_dim_g,
        decoder_h_dim=args.decoder_h_dim_g,
        mlp_dim=args.mlp_dim,
        num_layers=args.num_layers,
        noise_dim=args.noise_dim,
        noise_type=args.noise_type,
        noise_mix_type=args.noise_mix_type,
        pooling_type=args.pooling_type,
        pool_every_timestep=args.pool_every_timestep,
        dropout=args.dropout,
        bottleneck_dim=args.bottleneck_dim,
        neighborhood_size=args.neighborhood_size,
        grid_size=args.grid_size,
        batch_norm=args.batch_norm)
    generator.load_state_dict(checkpoint['g_state'])
    generator.cuda()
    generator.train()
    return generator


def evaluate(args, loader, generator, num_samples):
    with torch.no_grad():
        for batch in loader:
            batch = [tensor.cuda() for tensor in batch]
            (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel,
             non_linear_ped, loss_mask, seq_start_end) = batch

            min_x = torch.min(pred_traj_gt[:, :, 0].view(-1)).data
            max_x = torch.max(pred_traj_gt[:, :, 0].view(-1)).data
            min_y = torch.min(pred_traj_gt[:, :, 1].view(-1)).data
            max_y = torch.max(pred_traj_gt[:, :, 1].view(-1)).data

            for seq in seq_start_end:
                gt_track_data = np.array(pred_traj_gt[:, seq[0]:seq[1], :].data)
                obs_track_data = np.array(obs_traj[:, seq[0]:seq[1], :].data)
                for _ in range(1):#num_samples
                    pred_traj_fake_rel = generator(
                        obs_traj, obs_traj_rel, seq_start_end)
                    pred_traj_fake = relative_to_abs(
                        pred_traj_fake_rel, obs_traj[-1])
                    gen_track_data = np.array(pred_traj_fake[:, seq[0]:seq[1], :].data)

                global cf, ax, fake_graph, real_graph
                cf, ax = plt.subplots()
                ax.set_xlim(min_x * 1.1, max_x * 1.1)
                ax.set_ylim(min_y * 1.1, max_y * 1.1)
                __ = ax.plot(obs_track_data[:, 0], obs_track_data[:, 1], 'b.', alpha=0.5, label='observed')
                real_graph, = ax.plot([], [], 'g*', alpha=0.5, label='gt')
                fake_graph, = ax.plot([], [], 'ro', alpha=0.5, label='pred')

                global fake_tracks, real_tracks
                fake_tracks = gen_track_data
                real_tracks = gt_track_data
                anim = animation.FuncAnimation(cf, update_dot, gen_dot, interval=200)
                plt.legend()
                plt.show()
                plt.close()

                global cf_fakes_x, cf_fakes_y, cf_reals_x, cf_reals_y
                cf_fakes_x, cf_fakes_y = [], []
                cf_reals_x, cf_reals_y = [], []

def main(args):
    if os.path.isdir(args.model_path):
        filenames = os.listdir(args.model_path)
        filenames.sort()
        paths = [
            os.path.join(args.model_path, file_) for file_ in filenames
        ]
    else:
        paths = [args.model_path]

    for path in paths:
        checkpoint = torch.load(path)
        generator = get_generator(checkpoint)
        _args = AttrDict(checkpoint['args'])
        path = get_dset_path(_args.dataset_name, args.dset_type)
        _, loader = data_loader(_args, path)
        evaluate(_args, loader, generator, args.num_samples)



if __name__ == '__main__':
    args = parser.parse_args()
    main(args)
